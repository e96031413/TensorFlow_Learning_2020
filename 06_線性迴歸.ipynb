{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06.線性迴歸.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNNoh5XxnsqexEYMJ872Tun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e96031413/TensorFlow_Learning_2020/blob/master/06_%E7%B7%9A%E6%80%A7%E8%BF%B4%E6%AD%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEv2UP8vVcje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8e65d0d4-ed54-437e-ea35-47c2d680a97d"
      },
      "source": [
        "#交叉驗證\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "np.random.seed(7)  # 指定亂數種子\n",
        "# 載入波士頓房屋資料集\n",
        "df = pd.read_csv(\"./boston_housing.csv\")\n",
        "dataset = df.values\n",
        "np.random.shuffle(dataset)  # 使用亂數打亂資料\n",
        "# 分割成特徵資料和標籤資料\n",
        "X = dataset[:, 0:13]\n",
        "Y = dataset[:, 13]\n",
        "# 特徵標準化\n",
        "X -= X.mean(axis=0)\n",
        "X /= X.std(axis=0)\n",
        "# 分割訓練和測試資料集\n",
        "X_train, Y_train = X[:404], Y[:404]     # 訓練資料前404筆\n",
        "X_test, Y_test = X[404:], Y[404:]       # 測試資料後102筆\n",
        "# 定義模型\n",
        "def build_deep_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation=\"relu\"))\n",
        "    model.add(Dense(16, activation=\"relu\"))\n",
        "    model.add(Dense(1))\n",
        "    # 編譯模型\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", \n",
        "                  metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "k = 4\n",
        "nb_val_samples = len(X_train) // k\n",
        "nb_epochs = 80\n",
        "mse_scores = []\n",
        "mae_scores = []\n",
        "for i in range(k):\n",
        "    print(\"Processing Fold #\" + str(i))\n",
        "    # 取出驗證資料集\n",
        "    X_val = X_train[i*nb_val_samples: (i+1)*nb_val_samples]\n",
        "    Y_val = Y_train[i*nb_val_samples: (i+1)*nb_val_samples]\n",
        "    # 結合出訓練資料集\n",
        "    X_train_p = np.concatenate(\n",
        "            [X_train[:i*nb_val_samples],\n",
        "            X_train[(i+1)*nb_val_samples:]], axis=0)\n",
        "    Y_train_p = np.concatenate(\n",
        "            [Y_train[:i*nb_val_samples],\n",
        "            Y_train[(i+1)*nb_val_samples:]], axis=0)\n",
        "    model = build_deep_model()\n",
        "    # 訓練模型\n",
        "    model.fit(X_train_p, Y_train_p, epochs=nb_epochs, \n",
        "              batch_size=16, verbose=0)\n",
        "    # 評估模型\n",
        "    mse, mae = model.evaluate(X_val, Y_val)\n",
        "    mse_scores.append(mse)\n",
        "    mae_scores.append(mae)\n",
        "    \n",
        "print(\"MSE_val: \", np.mean(mse_scores))\n",
        "print(\"MAE_val: \", np.mean(mae_scores))\n",
        "# 使用測試資料評估模型\n",
        "mse, mae = model.evaluate(X_test, Y_test)    \n",
        "print(\"MSE_test: \", mse)\n",
        "print(\"MAE_test: \", mae)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Fold #0\n",
            "101/101 [==============================] - 0s 704us/step\n",
            "Processing Fold #1\n",
            "101/101 [==============================] - 0s 903us/step\n",
            "Processing Fold #2\n",
            "101/101 [==============================] - 0s 1ms/step\n",
            "Processing Fold #3\n",
            "101/101 [==============================] - 0s 1ms/step\n",
            "MSE_val:  18.426768534254318\n",
            "MAE_val:  2.846781608491841\n",
            "102/102 [==============================] - 0s 60us/step\n",
            "MSE_test:  8.395139236076206\n",
            "MAE_test:  2.166057037372215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWkD5Oc9VwVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "11896571-2b33-47a2-efaf-f1659b14b271"
      },
      "source": [
        "#無交叉驗證\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "np.random.seed(7)  # 指定亂數種子\n",
        "# 載入波士頓房屋資料集\n",
        "df = pd.read_csv(\"./boston_housing.csv\")\n",
        "dataset = df.values\n",
        "np.random.shuffle(dataset)  # 使用亂數打亂資料\n",
        "# 分割成特徵資料和標籤資料\n",
        "X = dataset[:, 0:13]\n",
        "Y = dataset[:, 13]\n",
        "# 特徵標準化\n",
        "X -= X.mean(axis=0)\n",
        "X /= X.std(axis=0)\n",
        "# 分割訓練和測試資料集\n",
        "X_train, Y_train = X[:404], Y[:404]     # 訓練資料前404筆\n",
        "X_test, Y_test = X[404:], Y[404:]       # 測試資料後102筆\n",
        "# 定義模型\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_shape=(X_train.shape[1],), activation=\"relu\"))\n",
        "model.add(Dense(32, activation=\"relu\"))\n",
        "model.add(Dense(1))\n",
        "# 編譯模型\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", \n",
        "              metrics=[\"mae\"])\n",
        "# 訓練模型\n",
        "model.fit(X_train, Y_train, epochs=80, batch_size=16, verbose=0)\n",
        "# 使用測試資料評估模型\n",
        "mse, mae = model.evaluate(X_test, Y_test)    \n",
        "print(\"MSE_test: \", mse)\n",
        "print(\"MAE_test: \", mae)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 521us/step\n",
            "MSE_test:  8.12880017710667\n",
            "MAE_test:  2.142300393067154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx7LKKevW1R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 儲存神經網路模型結構與權重\n",
        "\n",
        "## 方法1\n",
        "json_str = model.to_json()\n",
        "with open(\"Model.config\", \"w\") as text_file:\n",
        "  text_file.write(json_str)\n",
        "model.save_weights(\"Model.weight\")\n",
        "\n",
        "## 方法2\n",
        "model.save(\"Model.h5\")  #將模型結構與權重保存成單一檔案(HDF5格式*.h5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0ohR8aXZFPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 載入神經網路模型結構與權重\n",
        "\n",
        "##  方法1(分開載入)\n",
        "from keras.models import model_from_json\n",
        "\n",
        "model = Sequential()\n",
        "with open(\"Model.config\", \"r\") as text_file:\n",
        "  json_str = text_file.read()\n",
        "model = model_from_json(json_str)\n",
        "\n",
        "model.load_weights(\"Model.weight\", by_name=False)           #載入權重後還要compile()才能評估模型和計算預測值\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "##  方法2(一次載入)\n",
        "from keras.models import load_model\n",
        "\n",
        "model = Sequential()\n",
        "model = load_model(\"Model.h5\")\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}